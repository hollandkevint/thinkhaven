# Strategic Direction

*Updated February 2026 — Decision Architecture Evolution*

## Core Positioning

ThinkHaven is a **decision architecture platform** that owns the gap between "I have information" and "I know what to do." When build cost approaches zero, the bottleneck shifts from execution to specification and decision-making. ThinkHaven applies structured methodology to that bottleneck.

**The "Dashboards to Decisions" Thesis:**
Everyone has data, dashboards, ideas, and now GenAI agents that can build anything overnight. What they don't have is a structured way to decide what's worth building, whether their strategy holds up under pressure, or when to kill an idea before wasting months on it. ThinkHaven owns that decision layer.

**What ThinkHaven IS:**
- A decision architecture platform with opinionated pushback
- A problem design partner that helps articulate *what problem you're solving* before evaluating solutions
- An enforced methodology that can't be skipped
- A system that delivers polished, portable outputs

**What ThinkHaven is NOT:**
- A Claude wrapper with a persona
- A learning platform that teaches frameworks
- A project management tool
- A high-fidelity design tool
- Brainstorming without filtering

## Value Proposition

> "More structured than Claude, faster/cheaper than consultants, more strategic than Miro"

### The Problem We Solve

Most people don't know what they don't know about prompting. They accept sycophantic AI responses because they don't realize they should demand better. They build first, validate later, and waste months on the wrong thing.

GenAI agents make this worse, not better. They let you build on bad ideas faster. A cool mechanic doesn't make a great game — and a weekend prototype doesn't make a viable business.

Most people skip problem design entirely. They have a solution idea and work backwards to justify it. ThinkHaven forces the problem design work that LLMs cannot do alone — the collaborative framing that creates genuine understanding.

### Our Solution

ThinkHaven packages expert methodology into an AI-powered system that:
1. **Enforces structured thinking** - Users can't skip steps
2. **Provides genuine pushback** - Anti-sycophancy by design
3. **Delivers portable outputs** - Lean Canvas, PRD/Spec that travel to next tools
4. **Renders honest judgment** - Will recommend killing ideas when warranted

### Competitive Differentiation

| Competitor | What they offer | ThinkHaven's edge |
|------------|-----------------|-------------------|
| **Claude (skills/projects/Code)** | General AI with context management | Structured methodology + opinionated pushback + polished output |
| **Strategy consultants** | Human expertise, high-touch | 10-30 min vs. weeks, $25 vs. $5K+, available on-demand |
| **Miro/Figjam/Balsamiq** | Visual collaboration + AI features | Strategy-first with visuals as output, not canvas-first |
| **Free prompt kits / GPTs** | Templates without persistence | Persistent sessions, structured artifacts, session continuity |

**Moat:** Enforced methodology + sub-persona balancing + anti-sycophancy + polished portable outputs. Hard to DIY.

## Target Users — Two-Tier Model

### Entry Tier: Solo Entrepreneurs
**Who:** Solo founders, indie hackers, vibe coders shipping fast
**Job-to-be-done:** "Should I build this?" — validate before committing time
**Pain when skipped:** Months wasted building something nobody wants
**Success feeling:** "I pressure-tested this, I'm confident, I'm ready to build"
**Pricing:** $25/session
**Competitive frame:** Competes with free prompt kits by offering persistent outputs and session continuity

### Growth Tier: Executives & Product Leaders
**Who:** CPOs, VPs of Product, strategy team leads, consultants
**Job-to-be-done:** "Will this hold up in the room?" — stress-test strategy before high-stakes meetings
**Pain when skipped:** Walking into a board meeting with untested assumptions
**Success feeling:** "I have a partner that makes me sharper"
**Pricing:** $150-300/session
**Competitive frame:** Less competition from free alternatives. Higher willingness to pay. Natural fit for anti-sycophancy positioning.

### Shared Thesis

Both tiers share the same core problem: converting inputs (ideas, data, dashboards, market signals) into outputs (decisions, specs, go/no-go calls). The methodology is the same. The framing and pricing change.

## Market Validation Signals

### LinkedIn Thread Evidence (February 2026)

Alex Gutwillig's thread on "building on bad ideas faster with GenAI" generated strong engagement and directly validates ThinkHaven's positioning:

**Key quotes:**
- **Eduardo M.** shared "Monsieur Vibe" — an idea that sounds fun, builds fast in a weekend, and nobody needs. Exactly the pattern ThinkHaven's kill recommendation system addresses.
- **Jeff Arnold:** "A cool mechanic doesn't make a great game" — execution quality without validation is waste.

**What this signals:**
- Builders recognize the "bad ideas faster" problem in their own work
- The language people use maps directly to ThinkHaven's anti-sycophancy positioning
- Nobody in the thread proposes a structured solution — the gap ThinkHaven fills
- The pain is felt and articulated, but no tool addresses it yet

## Sub-Persona System

### The Four Modes

Every session includes all four modes, weighted by pathway:

| Mode | Role | Behavior |
|------|------|----------|
| **Inquisitive** | Dig deeper, understand context | Open-ended questions, explore assumptions |
| **Devil's Advocate** | Challenge assumptions, red-team | Push back on weak logic, probe blind spots |
| **Encouraging** | Validate good instincts | Acknowledge strong thinking, build confidence |
| **Realistic** | Ground in constraints | Time/resource reality, implementation feasibility |

### Pathway Weights

| Mode | New Idea | Business Model | Feature Refinement |
|------|----------|----------------|-------------------|
| Inquisitive | 40% | 20% | 25% |
| Devil's Advocate | 20% | 35% | 30% |
| Encouraging | 25% | 15% | 15% |
| Realistic | 15% | 30% | 30% |

### Mode Transitions

**Layer 1:** Pathway-weighted defaults (set at session start)
**Layer 2:** Dynamic shifting (AI reads the moment and adjusts)
**Layer 3:** User control (after ~10 exchanges, surface explicit options)

Dynamic shift triggers:
- User defensive → shift to Encouraging before returning to challenge
- User overconfident → lean into Devil's Advocate
- User spinning → bring in Realistic to ground

## Kill Decision Framework

ThinkHaven will recommend killing ideas when warranted. This is a key differentiator.

### Escalation Sequence

1. **Diplomatic flags** - "I see some significant risks here..."
2. **Deeper probe** - "Let me challenge this assumption..." (gives user chance to defend/pivot)
3. **Explicit recommendation** - "Based on what we've discussed, I don't think you should pursue this because..."
4. **Kill score** - Viability rating that makes the recommendation concrete

### Principle

Mary earns the right to kill an idea by doing the work first. She doesn't dismiss early - she explores, challenges, and THEN renders judgment.

## Session Experience

### Duration
10-30 minutes (not 3 minutes, not hour-long)

### Trial Flow
- 10 messages (up from current 5)
- Partial output provided at gate (value first)
- Full output + save + export requires signup

### The Feeling

Users should feel:
- **Invigorated** (not exhausted)
- **Confident** (not doubtful)
- **Momentum** (not analysis paralysis)

After session, they think:
- "I can imagine this" (friend/stakeholder viewing output)
- "I'm ready to build" (taking output to prototyping tool)
- "I want to do this again" (returning for next idea)

## Output Strategy

### MVP Outputs (Must Ship)

| Output | Purpose | Format |
|--------|---------|--------|
| **Lean Canvas** | Quick visual framework, pitch-ready | Structured markdown/PDF |
| **PRD/Spec** | Detailed working document, dev handoff | Structured markdown/PDF |

### Post-MVP Outputs

| Output | Purpose | Format |
|--------|---------|--------|
| **HTML Presentation** | Client-ready, shareable | Single-file HTML |
| **Low-fi Visuals** | Workflow diagrams, concept maps | Excalidraw-style sketches |

### Output Principle

**High polish:** Documents, specs (what you present to others)
**Low polish:** Wireframes, diagrams (thinking tools, not deliverables)

The canvas/visual workspace is **nice-to-have**, not critical. Text outputs carry the core value.

## Pricing Strategy

### Two-Tier Session Pricing

| Tier | Price | Audience | Value Prop |
|------|-------|----------|------------|
| **Entry** | $25/session | Solo entrepreneurs | "Should I build this?" — idea validation |
| **Growth** | $150-300/session | Executives / product leaders | "Will this hold up in the room?" — strategy stress-test |

### Launch Strategy

**Phase 1: Beta (Current)**
- Free beta access via waitlist + approval
- Goal: Validate methodology, collect feedback, build testimonials

**Phase 2: Entry Tier Launch**
- $25/session for solo entrepreneurs
- LTD option ($199-499) for early adopters

**Phase 3: Executive Tier**
- $150-300/session with premium positioning
- Consultants as a channel (they use it with clients)

### Future Consideration
- BYOK (Bring Your Own Key) tier for cost-conscious power users
- Subscription model for frequent users

## Build Status (February 2026)

### Completed

| Component | Status |
|-----------|--------|
| Sub-Persona System (types, weights, state detection) | 4/6 stories done, 67 tests |
| Dynamic Mode Shifting | Done (`switch_persona_mode` tool) |
| Anti-Sycophancy / Kill Recommendations | Done (`recommend_action` tool) |
| Output Polish (Lean Canvas + PRD) | Done (`generate_document` tool) |
| Agent-Native Tool System (9 tools, agentic loop) | Done |
| Beta Access Control (waitlist, JWT gating, approval) | Done |
| Error/Loading States (skeletons, retry, error display) | Done |
| MDX Blog (2 articles) | Done |
| Design System (Wes Anderson palette) | Done |
| Auth Migration to @supabase/ssr | Done |

### Remaining for MVP

| Component | Status |
|-----------|--------|
| 10-Message Trial Gate | Pending (Epic 6.5) |
| Mode Indicator UI | Pending (Epic 6.6) |
| Enable Tool Mode in UI | Pending |
| E2E Tests for Agentic Flow | Pending |

## Success Metrics (90-Day)

| Metric | Target | What it means |
|--------|--------|---------------|
| **Acquisition** | 100 signups | Enough volume to validate funnel |
| **Activation** | 50% complete session + output | 50 people get real value |
| **Revenue** | $2,000 | ~10-15 LTDs (proves willingness to pay) |
| **Retention** | 75% return for 2nd session | Methodology is working |

### Qualitative Signals
- Users report feeling "challenged but confident"
- Output is portable (users take it to prototyping tools)
- Consultants use it for multiple client engagements

## Anti-Goals

Explicit decisions about what NOT to build:

| Anti-Goal | Reason |
|-----------|--------|
| Claude wrapper with persona | If it feels like "ChatGPT with a hat," it failed |
| Learning platform | We apply frameworks, not teach them |
| Project management | We end at the decision, don't track execution |
| High-fidelity design | Sketches support strategy, polish goes to documents |
| Brainstorming without filtering | Ideation must include pushback and red-teaming |
| Real-time canvas sync | Text output is the core value; canvas is downstream |

---

*This document reflects strategic direction updated February 13, 2026, incorporating decision architecture evolution, two-tier audience model, and market validation signals.*
